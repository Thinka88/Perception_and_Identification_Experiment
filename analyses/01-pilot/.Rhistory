knitr::opts_chunk$set(echo = TRUE, cache = FALSE, message = FALSE, warning = FALSE, error = FALSE, fig.width = 5, fig.align = "center")
# check again, which libraries are really needed
# package for convenience functions (e.g. ggplot2, dplyr, etc.)
library(tidyverse)
# package for Bayesian regression modeling
library(brms)
# package for visualization
library(tidybayes)
# package to visualize
library(bayesplot)
# these options help Stan run faster
options(mc.cores = parallel::detectCores())
#devtools::install_github("michael-franke/aida-package")
library(aida)
# use the aida-theme for plotting
theme_set(theme_aida())
# global color scheme / non-optimized
project_colors = c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#000000")
# setting theme colors globally
scale_colour_discrete <- function(...) {
scale_colour_manual(..., values = project_colors)
}
scale_fill_discrete <- function(...) {
scale_fill_manual(..., values = project_colors)
}
data <- read_csv("results_271_XPLab+SS21+-+Group+13+-+Pilot_Mara,+Linus,+Cosima,+Katharina.csv")
glimpse(data)
# exclude test trials
data <- data %>%
filter(submission_id != 2391, submission_id != 2395, submission_id != 2396)
d_summary <- data %>%
group_by(submission_id) %>%
summarize(gender = unique(gender),
condition = unique(trial_name),
age = unique(age))
d_summary
data$comments %>% unique
# only include relevant columns
preprocessed_data <- data %>%
select(submission_id, trial_name, trial_number, switch_rate, correctness, RT, timeSpent, age, gender, languages, comments) %>%
# change trial_name to condition
rename(condition = trial_name) %>%
mutate(outlier = case_when(RT > 8000 ~ TRUE,
TRUE ~ FALSE))
# look at data points to exclude
ggplot(data = preprocessed_data, aes(x = trial_number, y = RT)) +
geom_point(alpha = 0.2) +
geom_point(data = filter(preprocessed_data, outlier == TRUE),
color = "firebrick", shape = "square", size = 2)
# exclude the outliers
clean_data <- filter(preprocessed_data, outlier == FALSE)
# number of outliers we exclude
preprocessed_data$outlier %>% sum()
# make clean data without outliers, RT, timeSpent
clean_data <- preprocessed_data %>%
select(submission_id, condition, switch_rate, correctness)
# make switch rate ordered factor
clean_data$switch_rate <- clean_data$switch_rate %>%
factor(ordered = TRUE)
# this is just to have the mean accuracy of each condition at hand
d <- clean_data %>%
group_by(condition) %>%
mutate(correct_response = ifelse(correctness == 'correct', 1, 0)) %>%
summarize(mean_accuracy = mean(correct_response))
d
# get overall accuracy for each condition (the same as above)
clean_data <- clean_data %>%
group_by(condition) %>%
mutate(correct_response = ifelse(correctness == 'correct', 1, 0),
condition_accuracy = mean(correct_response)) %>%
ungroup() %>%
# get accuracy for each switch rate and participant individually
group_by(submission_id, switch_rate) %>%
mutate(individual_swr_accuracy = mean(correct_response)) %>%
ungroup() %>%
# average individual switch_rate over all participants
group_by(switch_rate) %>%
mutate(average_swr_accuracy = mean(individual_swr_accuracy)) %>%
ungroup() %>%
group_by(condition, submission_id, switch_rate)
ggplot(data = clean_data, aes(x = switch_rate, y = average_swr_accuracy)) +
geom_point(aes(y = individual_swr_accuracy), alpha = 0.01) +
# use this to have smooth line
geom_smooth(method = "auto") +
# use this to have accurate line
#geom_line() +
# indicator for chance
geom_hline(aes(yintercept = 0.5), color = "darkred")
# something with facet_grid to display both conditions
# but this down below does not seem to work
#facet_wrap(~ condition, ncol = 1)
# fix our error by taking the three participants and inversing their accuracy
clean_data_fixing_our_error <- clean_data %>%
filter(submission_id == 2394 | submission_id == 2398 | submission_id == 2400) %>%
select(-condition_accuracy , -individual_swr_accuracy, -average_swr_accuracy) %>%
mutate(correctness = ifelse(correctness == 'correct', 'incorrect', 'correct'))
# all of the data collected after we fixed our error
clean_data <- clean_data %>%
filter(submission_id != 2394, submission_id != 2398, submission_id != 2400) %>%
select(-condition_accuracy, -individual_swr_accuracy, -average_swr_accuracy)
clean_data <- full_join(clean_data_fixing_our_error, clean_data)
clean_data <- clean_data %>%
ungroup() %>%
group_by(condition) %>%
mutate(correct_response = ifelse(correctness == 'correct', 1, 0),
condition_accuracy = mean(correct_response)) %>%
ungroup() %>%
# get accuracy for each switch rate and participant individually
group_by(submission_id, switch_rate) %>%
mutate(individual_swr_accuracy = mean(correct_response)) %>%
ungroup() %>%
# average individual switch_rate over all participants
group_by(switch_rate) %>%
mutate(average_swr_accuracy = mean(individual_swr_accuracy)) %>%
ungroup() %>%
group_by(condition, submission_id, switch_rate)
ggplot(data = clean_data, aes(x = switch_rate, y = average_swr_accuracy)) +
geom_point(aes(y = individual_swr_accuracy), alpha = 0.01) +
# use this to have smooth line
geom_smooth(method = "auto") +
# use this to have accurate line
#geom_line() +
# indicator for chance
geom_hline(aes(yintercept = 0.5), color = "darkred")
# something with facet_grid to display both conditions
# but this down below does not seem to work
#facet_wrap(~ condition, ncol = 1)
clean_data$condition_accuracy %>% unique()
model_1 <- brm(data = clean_data,
seed = 13,
# not sure about the random effects
formula = average_swr_accuracy ~ condition + switch_rate + (1|submission_id)
)
glm_logistic_regression <- brm(
formula = correctness ~ condition,
family = bernoulli(link = "logit"),
data = clean_data %>%
mutate(correctness = correctness == 'correct'),
prior = prior(student_t(1, 0, 1), class = 'b'),
sample_prior = 'yes',
iter = 20000)
pp_check(glm_logistic_regression)
brms::hypothesis(glm_logistic_regression, "conditionidentification = 0")
brms::hypothesis(glm_logistic_regression, "conditionidentification < 0")
brms::hypothesis(glm_logistic_regression, "conditionidentification > 0")
brms::hypothesis(glm_logistic_regression, "conditionidentification < 0")
glm_logistic_regression
logistic(1.81)
a <- (1+exp(-1.81))^-1
a
a <- (1+exp(-(1.81-0.27)))^-1
a
logistic_regression <- brm(
seed = 13,
formula = correctness ~ condition,
family = bernoulli(link = "logit"),
data = clean_data %>%
mutate(correctness = correctness == 'correct'),
prior = prior(student_t(1, 0, 1), class = 'b'),
sample_prior = 'yes',
iter = 20000)
pp_check(logistic_regression)
logistic_regression
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x)^-1))
}
logistic_regression$fixed
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x)^-1))
}
logistic_regression$fixed[, "Estimate"]
logistic_regression$fixed[, "Estimate"]
fixef(logistic_regression, pars = "Estimate")
fixef(logistic_regression)
fixef(logistic_regression)[,1]
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x)^-1))
}
fixef(logistic_regression)[1,1]
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x)^-1))
}
fixef(logistic_regression)[1,1]
fixef(logistic_regression)[1,2]
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x)^-1))
}
fixef(logistic_regression)[1,1]
fixef(logistic_regression)[2,1]
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x)^-1))
}
intercept <- fixef(logistic_regression)[1,1]
conditionIdentification <- fixef(logistic_regression)[2,1]
summary(discrimination = logistic(intercept),
identification = logistic(conditionIdentification))
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x)^-1))
}
intercept <- fixef(logistic_regression)[1,1]
conditionIdentification <- fixef(logistic_regression)[2,1]
d <- summary(discrimination = logistic(intercept),
identification = logistic(conditionIdentification))
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x)^-1))
}
intercept <- fixef(logistic_regression)[1,1]
conditionIdentification <- fixef(logistic_regression)[2,1]
d <- tibble(discrimination = logistic(intercept),
identification = logistic(conditionIdentification))
d
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x))^-1)
}
intercept <- fixef(logistic_regression)[1,1]
conditionIdentification <- fixef(logistic_regression)[2,1]
d <- tibble(discrimination = logistic(intercept),
identification = logistic(conditionIdentification))
d
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x))^-1)
}
intercept <- fixef(logistic_regression)[1,1]
conditionIdentification <- fixef(logistic_regression)[2,1]
d <- tibble(discrimination = logistic(intercept),
identification = logistic(intercept+conditionIdentification))
d
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x))^-1)
}
intercept <- fixef(logistic_regression)[1,1]
conditionIdentification <- fixef(logistic_regression)[2,1]
d <- tibble(discrimination = logistic(intercept),
identification = logistic(intercept+conditionIdentification))
d
clean_data$condition_accuracy %>% unique
#clean_data$condition_accuracy %>% unique()
clean_data$condition_accuracy[1]
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x))^-1)
}
intercept <- fixef(logistic_regression)[1,1]
conditionIdentification <- fixef(logistic_regression)[2,1]
d <- tribble(estimates_from, ~discrimination, ~identification,
model, logistic(intercept), logistic(intercept+conditionIdentification),
data, clean_data$condition_accuracy[1], clean_data$condition_accuracy[2])
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x))^-1)
}
intercept <- fixef(logistic_regression)[1,1]
conditionIdentification <- fixef(logistic_regression)[2,1]
d <- tribble(~estimates_from, ~discrimination, ~identification,
model, logistic(intercept), logistic(intercept+conditionIdentification),
data, clean_data$condition_accuracy[1], clean_data$condition_accuracy[2])
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x))^-1)
}
intercept <- fixef(logistic_regression)[1,1]
conditionIdentification <- fixef(logistic_regression)[2,1]
d <- tribble(~estimates_from, ~discrimination, ~identification,
"model", logistic(intercept), logistic(intercept+conditionIdentification),
"data", clean_data$condition_accuracy[1], clean_data$condition_accuracy[2])
d
#clean_data$condition_accuracy %>% unique()
clean_data$condition_accuracy[2]
#clean_data$condition_accuracy %>% unique()
clean_data$condition_accuracy[3]
#clean_data$condition_accuracy %>% unique()
clean_data$condition_accuracy %>% unique()
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x))^-1)
}
intercept <- fixef(logistic_regression)[1,1]
conditionIdentification <- fixef(logistic_regression)[2,1]
d <- tribble(~estimates_from, ~discrimination, ~identification,
"model", logistic(intercept), logistic(intercept+conditionIdentification),
"data", clean_data$condition_accuracy[1], clean_data$condition_accuracy[-1])
d
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x))^-1)
}
intercept <- fixef(logistic_regression)[1,1]
conditionIdentification <- fixef(logistic_regression)[2,1]
d <- tribble(~estimates_from, ~discrimination, ~identification,
"model", logistic(intercept), logistic(intercept+conditionIdentification),
"data", clean_data$condition_accuracy[1], clean_data$condition_accuracy[1])
d
#clean_data$condition_accuracy %>% unique()
clean_data$condition_accuracy["identification"]
#clean_data$condition_accuracy %>% unique()
unique(clean_data$condition_accuracy[2])
#clean_data$condition_accuracy %>% unique()
unique(clean_data$condition_accuracy)[2]
# predictor of central tendency
logistic <- function(x){
return((1+exp(-x))^-1)
}
intercept <- fixef(logistic_regression)[1,1]
conditionIdentification <- fixef(logistic_regression)[2,1]
estimates <- tribble(~estimates_from, ~discrimination, ~identification,
"model", logistic(intercept), logistic(intercept+conditionIdentification),
"data", unique(clean_data$condition_accuracy)[1], unique(clean_data$condition_accuracy)[2]
)
estimates
